---
title: "Transform"
output: github_document
---

<https://dplyr.tidyverse.org/>

## Setup

It's common to start a script using required packages and importing the data.

* Use tidyverse packages, which includes the package dplyr.

```{r setup}
library(tidyverse)
```

The dataset `gapminder` records human health and welth throught time.

```{r}
# Import
gapminder <- read_csv("data/gapminder.csv")

# View
gapminder
```



## Preview

Preview gapminder.

```{r}
# See also View(gapminder)
gapminder
```

Bored?

Compare 


You can also select a single variable from the data frame using the `$`:
```{r}
gapminder$year

head(gapminder$year)
```


### Exercise 

Insert an R chunk underneath this text and explore the gapminder dataset using 
the `names()`, `dim()`, `nrow()` and `ncol()` functions. 
* What are the column names? 
* How big is the dataset? 

Bored?
* Look at the helpfile for `?summary`. Try it out on gapminder
* Can you reverse engineer `dim()` using some other functions you know? 
* Hint: you'll need to remember vectors `c()`

## dplyr 

Let's start wrangling this large dataset using `dplyr`. 
This package has many incredibly useful functions, but we're going to focus on 
the five that you will probably use in every data science project that you work 
on: 

* `filter()`: pick observations by their values
* `select()`: pick variables by their names
* `mutate()`: create new variables with functions of existing variables
* `summarise()`: collapse many values down to a single summary
* `arrange()`: reorder the observations

First have a look at this very useful visual to help explain what these 
functions do:  https://i.imgur.com/uICSizl.png

* All of these functions take a data frame as their first argument
* The subsequent arguments describe what to do
* The result is a transformed data frame

## filter() observations

The filter function filters out rows of data, based on a "logical expression":

* The first argument is your dataset
* The second argument is a TRUE or FALSE question about one (or more) of the 
    variables

```{r}
# Let's say I only want data from 2002
# this will return all values from the gapminder data frame where the year is 2002
filter(gapminder, year == 2002)

```

Your turn!

Try to filter the gapminder data frame for observations where the life 
expectancy is less than 29:

```{r}
filter(gapminder, _____  ___ 29)
```

Hints:

* If you forget the column names, call names(gapminder)
* Remember the logical expressions from the last lesson:
    * `==` 
    * `!=` 
    * `<` 
    * `>` 
    * `<=` 
    * `=>` 

Bored?

* Filter for the year 2002
* What happens when you try to filter for the year 2021?
* Filter for observations where the `country` is "Cambodia"
* Challenge: Filter for all years between 1992 and 2002 
    (Hint: you will need %in% and seq())

Exercise: 

What is the mean life expectancy in Sweden? This problem might require using 
two functions, as well as the `$` operator. 

```{r}
gapminder_in_sweden <- filter(___, ___)
mean_life_expectency <- ______
```

## select() variables

We can select which variables we want to study with the `select()` function. 
Suppose we're only really interested in the country, year and life expectancy 
variables:
```{r}
select(gapfinder, country, year, lifeExp)
```

Rather than selecting the variables we DO want, we can also just drop the 
varaibles we DONT want by using a `-` sign. 
Suppose  we're not really interested in the population variable, and we can 
guess the continent variable from the country name? 

```{r}
select(gapfinder, -continent, -pop)
```

## Using filter() and select() together
Let's say we wanted to filter for "Cambodia" and remove the continent and 
lifeExp variables. We could do this in two steps: 

```{r}
gap_cambodia  <- filter(gapminder, country == "Cambodia")
gap_cambodia2 <- select(gap_cambodia, -continent, -lifeExp)
```

But this seems like a cumbersome process, especially for longer data pipelines.
Luckily, R has a more elegant solution. 

## Introducing the pipe operator

The pipe operator (which was imported by `dplyr` but actually comes from the 
`magrittr` package) is one of the most useful functions to exist in R, for data 
pipelines.

The operator looks like this `%>%`, and you can type it easily using the RStudio 
shortcut: Ctrl + Shift + M (Windows), Cmd + Shift + M (Mac)

First let's have a demo, and see if you can figure out how it works: 
```{r}
gapminder %>% head()
```

This looks equivalent to calling `head(gapminder)`> Let's see another example
```{r}
gapminder %>% head(3)
```

This looks like what you would expect from `head(gapminder,3)`. 
When you see `%>%` just think "and then". It passes the output from the 
left-hand side to the first argument of the right-hand side. Remember our example: 
```{r}
# instead of this...
gap_cambodia  <- filter(gapminder, country == "Cambodia")
gap_cambodia2 <- select(gap_cambodia, -continent, -lifeExp)

# we can do this
gap_cambodia  <- gapminder %>% filter(country == "Cambodia")
gap_cambodia2 <- gap_cambodia %>% select(-continent, -lifeExp)
```

We can actually take it one step further, and pipe this entire operation 
together: 
```{r}
# we can do this
gap_cambodia  <- gapminder %>% 
  filter(country == "Cambodia") %>% 
  select(-continent, -lifeExp)
```

Notice how I started a new line after every pipe call, and indent the next line? 
When R sees a pipe call at the end of a line, it knows to look for another 
indented function on the next line. This syntax can make reading R code a little 
closer to speaking english: 
"start with the gapminder data, and then
filter for Cambodia, and then
deselect the variables continent and lifeExp." 

Tidyverse was designed in such a way that all of it's verbs can work together in 
a pipeline. 

## mutate() adds a new variable

So far we have just been working with, and removing, variables and observations 
that already exist in the data. What if we wanted to add a new variable? 
For example, gapminder has a population variable and a GDP per capita variable, 
what if we wanted to recover the actual gdp? 

```{r}
# this just prints the output of the operation. 
gapminder %>%
  mutate(gdp = pop * gdpPercap)

# If i want to save it as an object to use later I have to assign it
gapminder_with_gdp <- gapminder %>%
  mutate(gdp = pop * gdpPercap)
```

### Exercise

Using the verbs we have learnt so far, and the pipe operator, find the maximum 
gdpPercap of Egypt and the maximum gdpPercap of Vietnam. Create a new column 
with mutate(). Hint: use max()

```{r}
# Egypt:
gapminder %>%
filter(___) %>%
mutate(___) %>%
mutate(___)

# Vietnam:
gapminder %>%
filter(___) %>%
mutate(___)
```

This is a little awkward. We have to copy and paste the exact same code twice, 
just to calculate the same thing for two different countries. 

## group_by() makes groups out of variables, that you can summarize()

How would we calculate gdpPercap at the country-level for all countries?

```{r}
gapminder %>%
  group_by(country) %>%
  mutate(gdp = pop * gdpPercap, max_gdp = max(gdp)) %>%
  ungroup() # if you use group_by, also use ungroup() to save heartache later
```

We now have a `max_gdp` column that shows the maximum GDP, by country, of every 
country in the dataset. But if you look closely, the values are repeated:

```{r}
gapminder %>%
  group_by(country) %>%
  mutate(gdp = pop * gdpPercap, max_gdp = max(gdp)) %>%
  ungroup() %>% # if you use group_by, also use ungroup() to save heartache later
  tail(30)
```

It is showing the maximum gdp for each country, but this value is indepdendent 
of year, so it shows the same value for every year. What if we want to collapse 
the data to only show the information we are interested in? 

This is where `summarise()` comes in. `group_by()` and `summarise()` are very 
commonly used together to perform tasks on groups of data, and distill the 
output: 

```{r}
gapminder %>%
  group_by(country) %>%
  mutate(gdp = pop * gdpPercap) %>%
  summarize(max_gdp = max(gdp)) %>%
  ungroup()
```

## arrange() arranges rows 

The gapminder dataset is organized in alphabetical order by country, but what if 
we wanted to arrange our new max_gdp dataset by decreasing max_gdp? 

```{r}
gapminder %>%
  group_by(country) %>%
  mutate(gdp = pop * gdpPercap) %>%
  summarize(max_gdp = max(gdp)) %>%
  ungroup() %>%
  arrange(max_gdp)
```

### Challenge 

* Arrange your data frame in descending order (opposite of what we’ve done). 
Expect that this is possible: see ?arrange for help
* Find the maximum life expectancy for countries in Asia. What is the earliest 
year you encounter? The latest? 
* Hint: you can use either base::max or dplyr::arrange()…

```{r}

```

## Putting it together

Before we get to the next module, I wanted to tease a full pipeline from import 
to summary: 

```{r}
# install libraries if necessary
# install.packages('tidyverse')

# load libraries
library(tidyverse)

# read in data
gapminder <- readr::read_csv('https://raw.githubusercontent.com/carpentries-incubator/open-science-with-r/gh-pages/data/gapminder.csv') 

## summarize
gap_max_gdp <- gapminder %>% 
  dplyr::select(-continent, -lifeExp) %>% # or select(country, year, pop, gdpPercap)
  dplyr::group_by(country) %>%
  dplyr::mutate(gdp = pop * gdpPercap) %>%
  dplyr::summarize(max_gdp = max(gdp)) %>%
  dplyr::ungroup() 
```

## Joining datasets

So far, we have only been working with one dataset. Before moving on, I want to 
talk to you briefly about joining two different datasets by a common variable.
T
here are different ways to do this. Suppose we have two datasets a and b, that 
we want to join together by the variable year.
We could: 
* Join all matching rows from b to a
* Join all matching rows from a to b
* Join both datasets, retaining only rows that are present in both a an b
* Join both datasets, retaining all rows and values in both datasets

To get a better idea of what I mean by this, check out this diagram: 
https://i.imgur.com/fV4St9d.png

This idea of "relational data" can take a second to click, so for now, I leave 
you to explore the following example. See if you can see for yourself what these 
different types of matching and joining can produce: 

```{r}
## read in the data.
co2 <- read_csv("https://raw.githubusercontent.com/carpentries-incubator/open-science-with-r/gh-pages/data/co2.csv")

## explore
co2 %>% head()
co2 %>% dim() # 12

## create new variable that is only 2007 data
gap_2007 <- gapminder %>%
  filter(year == 2007) 
gap_2007 %>% dim() # 142  

## left_join gap_2007 to co2
lj <- left_join(gap_2007, co2, by = "country")

## explore
lj %>% dim() #142
lj %>% summary() # lots of NAs in the co2_2017 columm
lj %>% View() 

## right_join gap_2007 and co2
rj <- right_join(gap_2007, co2, by = "country")

## explore
rj %>% dim() # 12
rj %>% summary()
rj %>% View() 
```

## Takeaways

* The filter() function subsets a dataframe by rows.

* The select() function subsets a dataframe by columns.

* The mutate function creates new columns in a dataframe.

* The group_by() function creates groups of unique column values.

* This grouping information is used by summarize() to make new columns that 
define aggregate values across groupings.

* The then pipe operator %>% allows you to chain successive operations without 
needing to define intermediary variables for creating the most parsimonious, 
easily read analysis.